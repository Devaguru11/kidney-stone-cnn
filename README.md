# ğŸ«˜ Kidney Stone Detection â€” CNN Project

> **Author:** devaguru  
> **Last Updated:** February 2026  
> **Overall Status:** Phases 1â€“3 Complete âœ… | Phase 4â€“6 Upcoming ğŸ”„

---

## ğŸ“Š Project Progress

| Phase | Description | Status | Duration |
|-------|-------------|--------|----------|
| 1 | Data Acquisition & Label Verification | âœ… Complete | ~2 Days |
| 2 | Model Training & First Experiments | âœ… Complete | ~3 Days |
| 3 | Evaluation & Explainability | âœ… Complete | ~2 Days |
| 4 | API Development (FastAPI) | ğŸ”„ Upcoming | â€” |
| 5 | Deployment (Docker + Kubernetes) | ğŸ”„ Upcoming | â€” |
| 6 | Monitoring & MLOps | ğŸ”„ Upcoming | â€” |

---

## ğŸ† Key Results

| Metric | Result | Target | Status |
|--------|--------|--------|--------|
| AUC-ROC | **1.0000** | â‰¥ 0.95 | ğŸ”¥ Exceeded |
| Sensitivity | **1.0000** | â‰¥ 0.92 | ğŸ”¥ Exceeded |
| Specificity | **0.9917** | â‰¥ 0.88 | ğŸ”¥ Exceeded |
| F2-Score | **0.9877** | â‰¥ 0.90 | ğŸ”¥ Exceeded |
| False Negatives | **0** | Minimise | ğŸ”¥ Zero missed stones |
| False Positives | **14** | < 5% of negatives | âœ… 0.83% |

> **Model:** EfficientNet-B4 + custom classification head Â· **Test set:** 1,904 images Â· **Zero missed stones**

---

## ğŸ“ Full Project Structure

```
kidney-stone-cnn/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/                        # Raw downloaded datasets (never modified)
â”‚   â”‚   â”œâ”€â”€ kidney_kaggle/
â”‚   â”‚   â”‚   â”œâ”€â”€ Stone/                   # 1,377 CT images (positive class)
â”‚   â”‚   â”‚   â”œâ”€â”€ Cyst/                    # CT images (mapped â†’ no_stone)
â”‚   â”‚   â”‚   â”œâ”€â”€ Normal/                  # CT images (mapped â†’ no_stone)
â”‚   â”‚   â”‚   â”œâ”€â”€ Tumor/                   # CT images (mapped â†’ no_stone)
â”‚   â”‚   â”‚   â””â”€â”€ kidneyData.csv
â”‚   â”‚   â””â”€â”€ kidney_ultrasound/
â”‚   â”‚       â”œâ”€â”€ stone/                   # Ultrasound positives
â”‚   â”‚       â””â”€â”€ Normal/                  # Ultrasound negatives
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                       # Clean 224Ã—224 preprocessed images
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”œâ”€â”€ stone/                   # 952 images
â”‚   â”‚   â”‚   â””â”€â”€ no_stone/               # 7,728 images
â”‚   â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”‚   â”œâ”€â”€ stone/                   # 201 images
â”‚   â”‚   â”‚   â””â”€â”€ no_stone/               # 1,661 images
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”‚       â”œâ”€â”€ stone/                   # 224 images
â”‚   â”‚       â””â”€â”€ no_stone/               # 1,680 images
â”‚   â”‚
â”‚   â””â”€â”€ labels/
â”‚       â”œâ”€â”€ splits.csv                   # Train/val/test assignment per image
â”‚       â”œâ”€â”€ annotations.json             # COCO-format metadata for all images
â”‚       â””â”€â”€ label_verification/
â”‚           â”œâ”€â”€ qa_report.txt
â”‚           â”œâ”€â”€ duplicates.json
â”‚           â”œâ”€â”€ class_distribution.png
â”‚           â”œâ”€â”€ sample_images.png
â”‚           â”œâ”€â”€ intensity_dist.png
â”‚           â””â”€â”€ test_results.png         # ROC curve + confusion matrix
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py                   # PyTorch Dataset class
â”‚   â”‚   â”œâ”€â”€ datamodule.py               # DataLoaders + WeightedRandomSampler
â”‚   â”‚   â””â”€â”€ augmentations.py            # Albumentations train/val transforms
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ efficientnet.py             # EfficientNet-B4 + classification head
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ losses.py                   # Focal Loss (Î³=2.0, Î±=0.75)
â”‚   â”‚   â”œâ”€â”€ metrics.py                  # Sensitivity, AUC, F2, confusion matrix
â”‚   â”‚   â””â”€â”€ trainer.py
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ gradcam.py                  # Grad-CAM++ heatmap generation
â”‚       â”œâ”€â”€ error_analysis.py           # False positive/negative visualisation
â”‚       â””â”€â”€ calibration.py             # Threshold optimisation + calibration curve
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ organize_data.py
â”‚   â”œâ”€â”€ preprocess_data.py
â”‚   â”œâ”€â”€ split_data.py
â”‚   â”œâ”€â”€ generate_annotations.py
â”‚   â”œâ”€â”€ verify_labels.py
â”‚   â”œâ”€â”€ train.py                        # Full training loop with MLflow
â”‚   â””â”€â”€ generate_report.py             # Auto-generates clinical HTML report
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                    # Phase 1 â€” Exploratory data analysis
â”‚   â”œâ”€â”€ 02_training.ipynb               # Phase 2 â€” Training monitoring
â”‚   â””â”€â”€ 03_gradcam.ipynb               # Phase 3 â€” Grad-CAM visualisations
â”‚
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ best_model.pth                  # Best model (val AUC = 1.0, epoch 7)
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ clinical_report.html            # Full clinical evaluation report
â”‚   â”œâ”€â”€ model_card.md                   # Regulatory model documentation
â”‚   â”œâ”€â”€ gradcam_stone.png
â”‚   â”œâ”€â”€ gradcam_no_stone.png
â”‚   â”œâ”€â”€ false_positives.png
â”‚   â”œâ”€â”€ threshold_curve.png
â”‚   â””â”€â”€ calibration_curve.png
â”‚
â”œâ”€â”€ mlruns/                             # MLflow experiment tracking
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ—ƒï¸ Datasets Used

### Dataset 1 â€” CT Kidney Dataset (Primary)
| Field | Detail |
|-------|--------|
| Source | Kaggle â€” CT KIDNEY DATASET: Normal-Cyst-Tumor-Stone |
| URL | kaggle.com/datasets/nazmul0087/ct-kidney-dataset-normal-cyst-tumor-and-stone |
| Total images | 12,446 |
| Format | JPEG, color |
| Original classes | Stone, Cyst, Normal, Tumor |
| License | CC BY 4.0 |

**Label mapping applied:**
| Original Class | Mapped To | Reason |
|---------------|-----------|--------|
| Stone | `stone` | Direct positive class |
| Cyst | `no_stone` | Different condition, not a stone |
| Normal | `no_stone` | Healthy kidney |
| Tumor | `no_stone` | Different pathology |

### Dataset 2 â€” Kidney Ultrasound Dataset
| Field | Detail |
|-------|--------|
| Source | Kaggle â€” Kidney Stone Ultrasound Image Dataset |
| URL | kaggle.com/datasets/safurahajiheidari/kidney-stone-ultrasound-image-dataset |
| Format | PNG/JPG |
| Classes | stone, Normal (already binary) |
| License | CC BY 4.0 |

---

## ğŸ“Š Dataset Statistics

| Split | Stone | No-Stone | Total | Stone % |
|-------|-------|----------|-------|---------|
| Train | 952 | 7,728 | 8,680 | 11.0% |
| Val | 201 | 1,661 | 1,862 | 10.8% |
| Test | 224 | 1,680 | 1,904 | 11.8% |
| **Total** | **1,377** | **11,069** | **12,446** | **11.1%** |

**Class imbalance:** 8.0:1 â€” handled with Focal Loss (Î³=2.0, Î±=0.75) + WeightedRandomSampler

---

## âœ… Phase 1 â€” Data Acquisition & Label Verification

### Preprocessing Applied
| Step | Operation | Parameters |
|------|-----------|------------|
| 1 | Resize | 224 Ã— 224 pixels, Lanczos interpolation |
| 2 | CLAHE | clipLimit=4.0, tileGridSize=(8,8) |
| 3 | Format | Saved as JPEG, BGRâ†’RGB corrected for display |

### Label Verification Results
| Check | Result | Detail |
|-------|--------|--------|
| âœ… Class balance | WARNING (expected) | 8.1:1 imbalance â€” handled in Phase 2 |
| âœ… Duplicate detection | WARNING (expected) | 2,579 sequential CT slice groups â€” not true duplicates |
| âœ… Corrupt / blank images | PASSED | 0 corrupt, 0 blank found |
| âœ… Train/test leakage | PASSED | No filename appears in both train and test |
| âœ… Image size consistency | PASSED | All sampled images are exactly (224, 224) |

### Split Strategy
Deterministic filename hashing (MD5) â€” same split every run, no random seed dependency, approximately 70/15/15 distribution.

```python
def stable_hash(filename: str) -> float:
    h = int(hashlib.md5(filename.encode()).hexdigest(), 16)
    return (h % 10000) / 10000.0
```

### Known Limitation
Without patient IDs, slices from the same patient may appear in both train and test. The leakage check confirmed no *identical* images appear across splits.

---

## âœ… Phase 2 â€” Model Training & First Experiments

### Model Architecture
| Component | Detail |
|-----------|--------|
| Backbone | EfficientNet-B4 (pretrained on ImageNet) |
| Head | AdaptiveAvgPool â†’ BN â†’ Dropout(0.4) â†’ Linear(1792â†’512) â†’ GELU â†’ Dropout(0.3) â†’ Linear(512â†’2) |
| Parameters | 18,471,242 |
| Loss | Focal Loss (Î³=2.0, Î±=0.75) |
| Optimiser | AdamW â€” backbone lr=1e-4, head lr=1e-3, weight_decay=1e-4 |
| Scheduler | CosineAnnealingLR |
| Device | Apple MPS (MacBook Air M-series) |

### Training Strategy
| Setting | Value | Reason |
|---------|-------|--------|
| Freeze backbone | Epochs 1â€“3 | Let head adapt to new task first |
| Unfreeze backbone | Epoch 4+ | Fine-tune entire network |
| Batch size | 8 | MPS memory constraint |
| Early stopping patience | 7 epochs | Stop if val AUC plateaus |
| Imbalance handling | WeightedRandomSampler | ~50/50 stone/no_stone per batch |

### Training Progress
| Epoch | AUC-ROC | Sensitivity | Note |
|-------|---------|-------------|------|
| 1 | 0.9086 | 0.9502 | Backbone frozen |
| 2 | 0.9296 | 0.9403 | Backbone frozen |
| 3 | 0.9578 | 0.9751 | Backbone frozen |
| 4 | 0.9965 | 0.9950 | Backbone unfrozen |
| 5 | 0.9996 | 0.9950 | Fine-tuning |
| 6 | 0.9998 | 0.9900 | Fine-tuning |
| **7** | **1.0000** | **1.0000** | **Converged â€” training stopped** |

### Final Test Set Results
| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| Sensitivity | 1.0000 | â‰¥ 0.92 | ğŸ”¥ Exceeded |
| Specificity | 0.9917 | â‰¥ 0.88 | ğŸ”¥ Exceeded |
| AUC-ROC | 1.0000 | â‰¥ 0.95 | ğŸ”¥ Exceeded |
| Precision | 0.9412 | â‰¥ 0.85 | âœ… Passed |
| F2-Score | 0.9877 | â‰¥ 0.90 | ğŸ”¥ Exceeded |
| True Positives | 224 | â€” | All stones detected |
| False Negatives | 0 | Minimise | ğŸ”¥ Zero |
| False Positives | 14 | â€” | 0.83% of negatives |
| True Negatives | 1,666 | â€” | â€” |

---

## âœ… Phase 3 â€” Evaluation & Explainability

### Grad-CAM Visual Explanations
Grad-CAM++ heatmaps generated for stone and no_stone test images using the last EfficientNet backbone block as the target layer. Heatmaps confirm the model focuses on kidney and urinary tract anatomy rather than image artifacts or borders.

Charts: `reports/gradcam_stone.png`, `reports/gradcam_no_stone.png`

### False Positive Analysis
14 false positives identified and visualised with Grad-CAM overlays. Common patterns:
- Cysts with high radiodensity mimicking stones
- Vascular calcifications outside the kidney
- Image compression artifacts triggering dense-region detector

**Clinical impact:** All 14 FPs would trigger follow-up imaging â€” no patient harm. Zero false negatives means zero missed stones.

Chart: `reports/false_positives.png`

### Threshold Calibration
Optimal decision threshold found on validation set using F2-score (Î²=2, weights recall 2Ã— over precision). Calibration curve confirms model probability estimates are well-calibrated.

Charts: `reports/threshold_curve.png`, `reports/calibration_curve.png`

### Clinical Report
Auto-generated HTML report at `reports/clinical_report.html`

```bash
open reports/clinical_report.html
```

---

## ğŸš€ How to Reproduce From Scratch

```bash
# 1. Clone and enter project
git clone <repo-url>
cd kidney-stone-cnn

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate   # Mac/Linux
# venv\Scripts\activate    # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Download datasets into data/external/
#    kidney_kaggle/  and  kidney_ultrasound/

# 5. Phase 1 â€” Data pipeline
python scripts/organize_data.py
python scripts/preprocess_data.py
python scripts/split_data.py
python scripts/generate_annotations.py
python scripts/verify_labels.py

# 6. Phase 2 â€” Train model
python scripts/train.py
# Best model saved to checkpoints/best_model.pth

# 7. Phase 3 â€” Evaluate and explain
# Run notebooks/03_gradcam.ipynb in VS Code
python scripts/generate_report.py
open reports/clinical_report.html
```

---

## ğŸ“¦ Dependencies

```
torch==2.2.0
torchvision==0.17.0
timm==0.9.16
pytorch-lightning==2.2.0
albumentations==1.3.1
mlflow==2.11.0
torchmetrics==1.3.1
grad-cam==1.5.0
opencv-python==4.9.0.80
scikit-learn==1.4.0
pandas==2.2.0
numpy==1.26.4
matplotlib==3.8.2
seaborn==0.13.2
Pillow==10.2.0
tqdm==4.66.2
imagehash==4.3.1
pydicom==2.4.3
SimpleITK==2.3.1
jupyter==1.0.0
ipykernel
pyarrow
```

---

## âš ï¸ Known Limitations

1. **No patient-level split** â€” Kaggle dataset has no patient IDs. Sequential CT slices from the same patient may appear in both train and test, which may inflate metrics. External validation recommended before clinical use.

2. **AUC = 1.0 caveat** â€” Perfect test score likely reflects CT slice similarity between splits rather than true generalisation. Must be validated on an independent external dataset before any clinical deployment.

3. **Low stone image count** â€” Only 952 stone training images. Rare stone variants (< 3mm, faint calcifications) may be underdetected. Adding TCIA data is recommended.

4. **No bounding box annotations** â€” Classification only. Stone localisation requires manual annotation via Label Studio or CVAT â€” deferred to a later phase.

5. **CT-heavy dataset** â€” Ultrasound images are underrepresented. Performance on ultrasound should be evaluated separately on a dedicated ultrasound test set.

---

## â¡ï¸ Next â€” Phase 4: API Development

Phase 4 wraps the trained model in a **FastAPI REST endpoint**:
- `POST /predict` â€” accepts an image, returns JSON with prediction, confidence score, and Grad-CAM heatmap
- `POST /predict/batch` â€” batch inference endpoint
- `GET /health` â€” health check
- Containerised with Docker for consistent cross-platform deployment

---

*Kidney Stone Detection CNN â€” Internal Research Project*
